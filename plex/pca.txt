# from sklearn.decomposition import PCA

# # Instantiating PCA
# pca = PCA()

# # Fitting and Transforming the DF
# df_pca = pca.fit_transform(new_df)

# # Plotting to determine how many features should the dataset be reduced to
# plt.style.use("bmh")
# plt.figure(figsize=(14,4))
# plt.plot(range(1,new_df.shape[1]+1), pca.explained_variance_ratio_.cumsum())
# plt.show()

# # Finding the exact number of features that explain at least 95% of the variance in the dataset
# total_explained_variance = pca.explained_variance_ratio_.cumsum()
# n_over_95 = len(total_explained_variance[total_explained_variance>=.95])
# n_to_reach_95 = new_df.shape[1] - n_over_95

# # Printing out the number of features needed to retain 95% variance
# print(f"Number features: {n_to_reach_95}\nTotal Variance Explained: {total_explained_variance[n_to_reach_95]}")

# # Reducing the dataset to the number of features determined before
# pca = PCA(n_components=n_to_reach_95)

# # Fitting and transforming the dataset to the stated number of features and creating a new DF
# df_pca = pca.fit_transform(new_df)

# # Seeing the variance ratio that still remains after the dataset has been reduced
# print(pca.explained_variance_ratio_.cumsum()[-1])


# hac.fit(df_pca)