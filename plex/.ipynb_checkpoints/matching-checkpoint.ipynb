{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c35afa31c78b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy; \n",
    "import boto3\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial import distance; \n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "client = boto3.client('s3')\n",
    "path = \"s3://misc.funpy/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(students, employers):\n",
    "    df = pd.read_csv(students)\n",
    "    df['Problem Solving'] = df['Rank each skill on the list first to last. [Problem Solving]'].astype(str).str[0]\n",
    "    df['Creativity'] = df['Rank each skill on the list first to last. [Creativity]'].astype(str).str[0]\n",
    "    df['Research'] = df['Rank each skill on the list first to last. [Research]'].astype(str).str[0]\n",
    "    df['Time Management'] = df['Rank each skill on the list first to last. [Time Management]'].astype(str).str[0]\n",
    "    df['Communication'] = df['Rank each skill on the list first to last. [Communication]'].astype(str).str[0]\n",
    "    # df['Critical Thinking'] = df[' [Critical Thinking]'].astype(str).str[0]\n",
    "\n",
    "    newdf = df[['Problem Solving', 'Creativity', 'Research', 'Time Management', 'Communication']]\n",
    "    newdf['Problem Solving'].replace(\"n\", value=\"0\", inplace=True)\n",
    "    newdf['Creativity'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Research'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Time Management'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Communication'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    # print(newdf)\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    new_df = pd.DataFrame(scaler.fit_transform(newdf), columns=newdf.columns[:], index=newdf.index)\n",
    "\n",
    "    # print(new_df)\n",
    "    # Setting the amount of clusters to test out\n",
    "    cluster_cnt = [i for i in range(2, 12, 1)]\n",
    "\n",
    "    # Establishing empty lists to store the scores for the evaluation metrics\n",
    "    s_scores = []\n",
    "\n",
    "    db_scores = []\n",
    "\n",
    "    # Looping through different iterations for the number of clusters\n",
    "    for i in cluster_cnt:\n",
    "        \n",
    "        # Hierarchical Agglomerative Clustering with different number of clusters\n",
    "        hac = AgglomerativeClustering(n_clusters=i)\n",
    "        \n",
    "        hac.fit(new_df)\n",
    "        \n",
    "        cluster_assignments = hac.labels_\n",
    "        \n",
    "        ## KMeans Clustering with different number of clusters\n",
    "        k_means = KMeans(n_clusters=i)\n",
    "        \n",
    "        k_means.fit(new_df)\n",
    "        \n",
    "        cluster_assignments = k_means.predict(new_df)\n",
    "        \n",
    "        # Appending the scores to the empty lists    \n",
    "        s_scores.append(silhouette_score(new_df, cluster_assignments))\n",
    "        \n",
    "        db_scores.append(davies_bouldin_score(new_df, cluster_assignments))\n",
    "    return [s_scores, db_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation(y, x=[i for i in range(2, 12, 1)]):\n",
    "    \"\"\"\n",
    "    Plots the scores of a set evaluation metric. Prints out the max and min values of the evaluation scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a DataFrame for returning the max and min scores for each cluster\n",
    "    df = pd.DataFrame(columns=['Cluster Score'], index=[i for i in range(2, len(y)+2)])\n",
    "    df['Cluster Score'] = y\n",
    "    \n",
    "    print('Max Value: Cluster #', df[df['Cluster Score']==df['Cluster Score'].max()])\n",
    "    print('\\nMin Value: Cluster #', df[df['Cluster Score']==df['Cluster Score'].min()])\n",
    "    print('\\n')\n",
    "    \n",
    "    # Plotting out the scores based on cluster count\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('# of Clusters')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "    return df[df['Cluster Score']==df['Cluster Score'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(csv, num_clusters, etc=None):\n",
    "    df = pd.read_csv(csv)\n",
    "    # print(df['Rank each skill on the list first to last. [Problem Solving]'])\n",
    "    df['Problem Solving'] = df['Rank each skill on the list first to last. [Problem Solving]'].astype(str).str[0]\n",
    "    df['Creativity'] = df['Rank each skill on the list first to last. [Creativity]'].astype(str).str[0]\n",
    "    df['Research'] = df['Rank each skill on the list first to last. [Research]'].astype(str).str[0]\n",
    "    df['Time Management'] = df['Rank each skill on the list first to last. [Time Management]'].astype(str).str[0]\n",
    "    df['Communication'] = df['Rank each skill on the list first to last. [Communication]'].astype(str).str[0]\n",
    "    # df['Critical Thinking'] = df[' [Critical Thinking]'].astype(str).str[0]\n",
    "\n",
    "    newdf = df[['Problem Solving', 'Creativity', 'Research', 'Time Management', 'Communication']]\n",
    "    newdf['Problem Solving'].replace(\"n\", value=\"0\", inplace=True)\n",
    "    newdf['Creativity'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Research'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Time Management'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Communication'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    # print(newdf)\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    # print(df)\n",
    "    new_df = pd.DataFrame(scaler.fit_transform(newdf), columns=newdf.columns[:], index=newdf.index)\n",
    "\n",
    "    # print(new_df)\n",
    "\n",
    "    clustering = AgglomerativeClustering(num_clusters)\n",
    "\n",
    "    # Fitting\n",
    "    clustering.fit(new_df)\n",
    "\n",
    "    # Getting cluster assignments\n",
    "    cluster_assignments = clustering.labels_\n",
    "\n",
    "    # Unscaling the categories then replacing the scaled values\n",
    "    if 'Best email to reach you' in df.columns:\n",
    "        df = df[['Best email to reach you']].join(pd.DataFrame(scaler.inverse_transform(newdf), columns=newdf.columns[:], index=newdf.index))\n",
    "    else:\n",
    "        df = df[['Company Name']].join(pd.DataFrame(scaler.inverse_transform(newdf), columns=newdf.columns[:], index=newdf.index))\n",
    "    # Assigning the clusters to each profile\n",
    "    df['Cluster #'] = cluster_assignments\n",
    "\n",
    "    # Viewing the dating profiles with cluster assignments\n",
    "    # print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(students, employers, num_clusters):\n",
    "    from clustering import cluster; import pandas as pd; import numpy as np; import scipy; from scipy.spatial import distance; from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "    clusteredEmployers = cluster(employers, num_clusters)\n",
    "\n",
    "    clusteredStudents = cluster(students, num_clusters)\n",
    "\n",
    "    for index, employer in clusteredEmployers.iterrows():\n",
    "        cluster = employer['Cluster #']\n",
    "        filtered_students = clusteredStudents[clusteredStudents['Cluster #'] == cluster]\n",
    "        best_student = \"\"\n",
    "        most_similar = -1\n",
    "        for index, student in filtered_students.iterrows():\n",
    "            arr = employer.values.tolist()\n",
    "            student_arr = student.values.tolist()\n",
    "            employer_values = np.array(arr[1:])\n",
    "            student_values = np.array(student_arr[1:])\n",
    "            cosine = cosine_similarity(employer_values.reshape(1, -1), student_values.reshape(1, -1))[0][0]\n",
    "            if cosine > most_similar:\n",
    "                most_similar = cosine\n",
    "                best_student = student_arr[0]\n",
    "        print(\"The best student for \" + employer['Company Name'] + \" is \" + best_student + \". This student has a \" + str(round(most_similar * 100, 1)) + \"% similarity to the company's preferences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = path + \"Student_Registration.csv\"\n",
    "employers = path + \"CORRECT_Employer_Full_Registration.csv\"\n",
    "num_clusters = int(input(\"Enter number of clusters you wish to cluster into: \"))\n",
    "s_scores = optimize(students, employers)[0]\n",
    "db_scores = optimize(students, employers)[1]\n",
    "s_score_num_clusters = plot_evaluation(s_scores)\n",
    "db_score_num_clusters = plot_evaluation(db_scores)\n",
    "print(\"Silhouette Score Optimization: \")\n",
    "match(students, employers, s_score_num_clusters)\n",
    "print(\"\\n \\n \\n\")\n",
    "print(\"Davies-Bouldin Score Optimization: \")\n",
    "match(students, employers, db_score_num_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
